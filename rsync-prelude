#!/usr/bin/env python3
"""
Fix moved/renamed files before running rsync to avoid useless retransmissions.

Copyright (C) 2022 Anton Pirogov, gbabin and Contributors, licensed under the MIT License
"""
from itertools import chain
from typing import List, Dict, Optional, Set, Tuple, Union
from dataclasses import dataclass
from pathlib import Path
from datetime import datetime
from shlex import quote
import argparse
import logging
import subprocess
import sys


def arg_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(prog=Path(__file__).name,
                                     description=__doc__,
                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument("-v", "--verbose", action="store_true", default=False)
    parser.add_argument("-q", "--quiet", action="store_true", default=False,
                        help="Do not print actions taken")
    parser.add_argument("-s", "--script", action="store_true", default=False,
                        help="Just output script executing detected moves ('dry run')")
    parser.add_argument("-e", "--rsh", default="ssh",
                        help="rsync remote shell command to use")
    parser.add_argument("-f", "--filter-args", default="",
                        help="rsync args affecting file list")
    parser.add_argument("--hash-tool", default="sha256sum",
                        help="Command to hash files. First word of the output must be the hash. It must be available on both source and target host(s)")
    parser.add_argument("--mv-cmd", default="mv -n",
                        help="Command used to move files")
    parser.add_argument("--cp-cmd", default="cp -n",
                        help="Command used to copy files")
    parser.add_argument("-t", "--no-timestamp", action="store_true",
                        help="Do not fix timestamp for moved or copied files")
    parser.add_argument("_src")
    parser.add_argument("_dest")
    return parser


def set_logger(args: argparse.Namespace) -> None:
    if args.quiet:
        level = logging.ERROR
    elif args.verbose:
        level = logging.INFO
    else:
        level = logging.WARNING  # default

    logging.basicConfig(stream=sys.stderr, level=level, format='%(message)s')


def verify_args(args) -> None:
    for root in (args._src, args._dest):
        if "::" in root.split("/")[0]:
            raise ValueError("'::' syntax is not supported.")

def main() -> None:
    global verbose

    args = arg_parser().parse_args()
    set_logger(args)

    verify_args(args)

    # Ensure last slashes of src and dest
    normalize_root(args)

    # get list of candidates both locally and on remote
    src_files, dst_files = rsync_list(args, args.SRC), rsync_list(args, args.DEST)

    files = Files(args, src_files, dst_files)

    logging.info("---- find moved/renamed files: ----")

    moves = compute_moves(files)

    logging.info("-------- required actions: --------")

    for cmd, src, trg in moves:
        logging.info(f"{cmd} {quote(src)} {quote(trg)}")

    logging.info("-------- perform  actions: --------")

    for move in moves:
        cmd = dst_cmd(args, *move)
        logging.warning(f"{cmd}")  # only omit cmd when asked to; if something goes wrong, it helps debugging
        if not args.script:
            run(cmd)

    logging.info("-----------------------------------")

# ----

@dataclass
class FileInfo:
    # parsed from output
    filename: str
    permissions: str
    size: int
    date: str
    time: str

    # for candidates:
    # additionally computed hashsum, or the size if it is unique in file set
    hashsum: Optional[str]

    @property
    def is_dir(self) -> bool:
        return self.permissions[0] == "d"

    @property
    def timestamp(self) -> str:
        t = datetime.strptime(f"{self.date} {self.time}", '%Y/%m/%d %H:%M:%S')
        return t.strftime("%Y%m%d%H%M.%S")


@dataclass
class Files:
    args: argparse.Namespace
    src: Dict[str, FileInfo]
    dest: Dict[str, FileInfo]

    def unpack(self):
        return self.args, self.src, self.dest

    def hash_to_path(self, fileinfos) -> Dict[str, List[str]]:
        ret: Dict[str, List[str]] = {}
        for p, i in fileinfos.items():
            if i.hashsum is None:
                continue
            if i.hashsum not in ret:
                ret[i.hashsum] = []
            ret[i.hashsum].append(p)
        return ret


@dataclass
class Diffs:
    added: Set[str]
    modified: Set[str]
    removed: Set[str]

# ----

def run(cmd: str, check: bool=True) -> bytes:
    """Run command and return standard output."""
    logging.info(f"run: {cmd}")
    return subprocess.run(cmd, shell=True, check=check, capture_output=True).stdout

def rsync_list_cmd(args, dir: str) -> str:
    """Command to list rsync candidate files."""
    if args.rsh == 'ssh' or is_local(dir):
        return f"rsync {args.filter_args} --list-only --no-human-readable {dir}"
    else:
        return f"rsync {args.filter_args} -e '{args.rsh}' --list-only --no-human-readable {dir}"

def rsync_list(args, dir: str) -> Dict[str, FileInfo]:
    """Return FileInfo objects for each rsync candidate."""
    output = run(rsync_list_cmd(args, dir))
    lines = output.decode("utf-8").splitlines()
    parsed = [l.split(maxsplit=4) for l in lines]
    ret = {}
    for perm, size, date, time, path in parsed:
        ret[path] = FileInfo(Path(path).name, perm, int(size), date, time, hashsum=None)
    return ret

def hashsum(args, root, path: str) -> Optional[str]:
    """Compute hashsum of a file (at source or target)."""
    filepath = fullpath(root, path)
    cmd = wrap_cmd(args, root, f"{args.hash_tool} {quote(filepath)}")

    ret = run(cmd, check=False)
    if not ret:
        return None
    else:
        return ret.decode("utf-8").split()[0]

def dst_cmd(args, cmd: str, arg1: str, arg2: str) -> str:
    root: str = args.DEST
    if cmd == "touch":
        timestamp = arg1
        trg_path = arg2
        trg = fullpath(root, trg_path)
        command = f"touch -c -t {timestamp} {quote(trg)}"
        return wrap_cmd(args, root, command)
    else:
        src_path = arg1
        trg_path = arg2
        src, trg = fullpath(root, src_path), fullpath(root, trg_path)
        trgdir = "/".join(trg.split("/")[:-1]) or "."
        command = f"mkdir -p {quote(trgdir)} && {cmd} {quote(src)} {quote(trg)}"
        return wrap_cmd(args, root, command)

# ----

def normalize_root(args) -> None:
    args.SRC = args._src.rstrip("/") + "/"
    dest = args._dest.rstrip("/") + "/"
    if args._src.endswith("/"):
        args.DEST = dest
    else:
        lastdir = args._src.split('/')[-1]
        if lastdir in ('.', '..'):  # rsync (or shell) treats e.g. '.' as './'
            args.DEST = dest
        else:
            args.DEST = f"{dest}{lastdir}/"

def is_local(root: str) -> bool:
    return root.split("/")[0].find(":") < 0

def get_host_and_root(root: str) -> Tuple[str, str]:
    if is_local(root):
        return '', root
    else:
        remote_host, root = root.split(":", maxsplit=1)
        return remote_host, root

def fullpath(root: str, path: str) -> str:
    remote_host: str
    remote_host, root = get_host_and_root(root)
    return f"{root}{path}"

def wrap_cmd(args, root: str, cmd: str) -> str:
    remote_host: str
    remote_host, root = get_host_and_root(root)
    if not remote_host:
        return cmd
    else:
        cmd_pref = f"{args.rsh} {remote_host} "
        return f"{cmd_pref} {quote(cmd)}"

# ----

def classify_paths(files: Files) -> Diffs:
    args, src_files, dst_files = files.unpack()

    added, removed, modified = set(), set(), set()
    for path in set.union(set(src_files.keys()), set(dst_files.keys())):
        in_src, in_trg = path in src_files, path in dst_files
        if in_src and not in_trg:
            added.add(path)
        elif in_trg and not in_src:
            removed.add(path)
        elif in_src and in_trg:
            src_file, dst_file = src_files[path], dst_files[path]

            # if file -> dir / dir -> file, this entity was modified
            diff_dirfile = src_file.is_dir != dst_file.is_dir
            # if size is different, it could still be e.g. part of linear/circular move
            # for bigger files, probability of different "real" files to be same size
            # is very small -> almost as good as hashsum to detect difference
            # for small files does not matter, they can be transferred fast anyway
            diff_size = src_file.size != dst_file.size

            if diff_size or diff_dirfile:
                modified.add(path)

    for path in set.union(added, modified):
        src = src_files[path]
        if src.is_dir or src.hashsum:
            logging.info(f"{path}: skip (dir or unique file size)")
            continue
        src.hashsum = hashsum(args, args.SRC, path)
    for path in set.union(removed, modified):
        dst = dst_files[path]
        if dst.is_dir or dst.hashsum:
            logging.info(f"{path}: skip (dir or unique file size)")
            continue
        dst.hashsum = hashsum(args, args.DEST, path)

    return Diffs(added, modified, removed)


def resolve_moves(files: Files, diffs: Diffs) -> List[List[str]]:
    args, src_files, dst_files = files.unpack()
    added, modified, removed = diffs.added, diffs.modified, diffs.removed

    # reverse lookup of paths by hashsum
    h_to_src_file = files.hash_to_path(src_files)
    h_to_trg_file = files.hash_to_path(dst_files)

    # get hashsums of files that were possibly moved:
    # hashsums of new or mod paths in source
    src_hsums = {src_files[p].hashsum for p in set.union(added, modified)}
    # hashsums of removed or mod paths in target
    trg_hsums = {dst_files[p].hashsum for p in set.union(removed, modified)}
    # these were moved (hashsum with different paths, exist in target):
    moved_hsums = set.intersection(src_hsums, trg_hsums)
    # compute moves to perform in target
    ret_direct, ret_pre, ret_post = [], [], []
    for h in moved_hsums:
        if not h:
            continue
        src_path = h_to_trg_file[h][0]  # any file with that hashsum is ok
        trg_path, copies = h_to_src_file[h][0], h_to_src_file[h][1:]

        if trg_path not in dst_files:
            ret_direct.append([args.mv_cmd, src_path, trg_path])
        else:
            ret_pre.append([args.mv_cmd, src_path, trg_path + "_tmp"])
            ret_post.append([args.mv_cmd, trg_path + "_tmp", trg_path])

        if not args.no_timestamp:
            timestamp = src_files[trg_path].timestamp
            ret_post.append(["touch", timestamp, trg_path])

        for trg_copy in copies:
            if trg_copy in dst_files:
                ret_pre.append([args.mv_cmd, trg_copy, trg_copy + "_old"])
            ret_post.append([args.cp_cmd, trg_path, trg_copy])

            if not args.no_timestamp:
                timestamp = src_files[trg_copy].timestamp
                ret_post.append(["touch", timestamp, trg_copy])
    # return sequence of shell commands in correct order
    return ret_direct + ret_pre + ret_post

def compute_moves(files: Files) -> List[List[str]]:
    _, src_files, dst_files = files.unpack()

    # figure out which file size is unique
    sizes: Dict[int, Set[str]] = {} # size -> filename
    for path, info in chain(src_files.items(), dst_files.items()):
        if info.size not in sizes:
            sizes[info.size] = set()
        sizes[info.size].add(path)

    # use file size as hashsum replacement if it is unique
    unique_sizes = { size for size, names in sizes.items() if len(names)<2 }
    for path, info in chain(src_files.items(), dst_files.items()):
        if info.size in unique_sizes:
            info.hashsum = str(info.size)

    # get hashsums for files that might have been moved (will compute hashsum for these)
    # these are files that exist only in src/dest or that look modified (diff. size)
    diffs = classify_paths(files)

    return resolve_moves(files, diffs)

# ----

if __name__ == "__main__":
    main()
